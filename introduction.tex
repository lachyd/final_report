\documentclass[capstone_report.tex]{subfiles}
\begin{document}
\chapter{Introduction}

\section{Overview and background}

\subsection{Motivation of problem}
The Metropolitan Fire Brigade (MFB) provides fire and emergency services to almost three million Melbourne residents in the metropolitan district \cite{mfb}.  Although primarily known for dealing with fires, their roles and responsibilities extend to other emergencies including chemical spillages, car crashes, hostage situations and post fire investigations.\\

A common theme amongst these scenarios is the expectation for firefighters to enter adverse conditions where they have little or no prior knowledge. Examples of this may include; smoke filled environments (low visibility), entering structurally unsound areas, locating and extinguishing small fires, responding to chemical spillages without knowledge of the contents or taming fires that may have toxic smoke.\\

One avenue that the MFB has begun exploring is drone technology.  In particular, off the shelf DJI drones fitted with thermal and visible light cameras have been providing the MFB with a birds eye perspective of response scenes \cite{mfb_drone}. This use of technology is a significant advantage over traditional ladder platforms that are limited by their observation height and do not carry the required sensors for thermal and plume analysis. During its pilot program, their drones have been successfully deployed in a number emergency situations. A few examples are given below:
\begin{enumerate}
    \item \textbf{Coolaroo Recycling Plant}: A recycling plant in Melbourne's Northern suburbs caught fire releasing toxic smoke ultimately resulting in the evacuation of 100 residents.
    \item \textbf{Citylink Truck Accident}: One incident on Melbourne's Citylink saw a truck crash into a brige in a way that part of it was obscured from view. A drone provided images to examine vehicle before removal.
    \item \textbf{Post Fire Investigation}  - Aerial images provide evidence in a coroners report.
\end{enumerate}

All examples given above were outdoor operations. The current state of the program relies solely on manual operation. Indoor environments are more challenging for human pilots to navigate as consideration needs to be given to stationary and moving obstacles, tighter constraints on flyable areas (doorways, windows) and obscured line of sight to drone. In addition, indoor environments impose harsher operating conditions including higher temperatures and limited visibility from smoke. As a result MFB currently does not currently operate any drones indoors. Despite this, indoor scenarios make up a considerable portion of emergency situations, particularly those where personnel are exposed to hazardous environments.\\

\subsection{Project objective}
The objective of this project was to develop an autonomous, indoor unmanned aerial vehicle (UAV),  which does not require direct control by a trained UAV pilot. The UAV must be capable of reporting a live video feed of its current observation, as well as constructing a floor map of the area in which it is flying. Navigation algorithms need to ensure that the UAV does not hit any static or moving obstacles as it moves towards goals.\\

The individual components of such a system are well known in the literature, and include UAV flight controllers, sensor fusion algorithms, simultaneous localization and mapping algorithms, and navigation algorithms. Many of these components are available as open source components, and can be treated as a `black box' (where only the inputs and outputs need to be known) or as a `gray box' (where some details of the algorithm need to be known for configuration or modification purposes). As a result, the focus of this project is on system design and system integration to achieve a desired result, with less focus devoted to theoretical treatment of each component.\\

\subsection{Report structure}
This report is structured into six chapters. 
\begin{enumerate}
    \item This first chapter focuses on the background to the project, and the formal requirements/success criteria. 
    \item The second chapter focuses on the literature review undertaken in relation to indoor autonomous UAVs and their component systems. 
    \item The third chapter documents the design process of the system. 
    \item The fourth chapter details our implementation methodology and issues encountered during implementation. 
    \item Test results are provided in the fifth chapter. 
    \item Our conclusions and areas for future research are presented in the final sixth chapter.\\
\end{enumerate}

Appendices are provided, including datasheets for all relevant components. Due to the volume of code developed, code has not been provided but is available on GitHub at \url{http://www.github.com/ursa-drone}.

\section{Scope of project}
The scope of the project was to deliver a prototype UAV which achieves the following functionality:
\begin{enumerate}
	\item \textbf{Autonomous navigation to a destination:} It was required that URSA would operate without control from a pilot and only based on a destination input from a base station. This removes the issues that arise from human error or obscured vision of the drone.
	\item \textbf{Avoidance of obstacles whilst in operation:} URSA should be able to avoid collisions with both static and dynamic obstacles within an indoor environment, based on sensor readings.
	\item \textbf{A live image/video feed of an indoors environment:} URSA was to obtain vision of the environment, so hazards and fire sources can be spotted.
	\item \textbf{A live 2D mapping of an indoors environment:} URSA was required to generate an accurate visualisation of the layout of the environment in order to guide decision making.
\end{enumerate}


The above list summarises the main scope of this project. However, achieving these alone would not likely guarantee a `final' product which could be deployed. There are many areas for future development which would be required in order to achieve a real-world product. These are discussed in the conclusion of this report.  

\end{document}